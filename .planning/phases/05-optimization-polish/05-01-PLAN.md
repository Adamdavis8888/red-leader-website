---
phase: 05-optimization-polish
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/sitemap.ts
  - app/robots.ts
  - app/lib/structured-data.ts
  - app/layout.tsx
  - app/(marketing)/page.tsx
  - app/(marketing)/services/page.tsx
  - app/(marketing)/services/[slug]/page.tsx
  - app/(marketing)/about/page.tsx
  - app/(marketing)/contact/page.tsx
  - app/(marketing)/case-studies/page.tsx
  - app/(marketing)/case-studies/[slug]/page.tsx
  - app/(marketing)/blog/page.tsx
  - app/(marketing)/blog/[slug]/page.tsx
autonomous: true

must_haves:
  truths:
    - "Search engines can discover all public pages via sitemap.xml"
    - "Search engines respect crawl directives via robots.txt"
    - "Rich snippets appear in search results with structured data"
    - "Each page has unique meta title and description"
  artifacts:
    - path: "app/sitemap.ts"
      provides: "Dynamic sitemap generation"
      exports: ["default"]
    - path: "app/robots.ts"
      provides: "Robots.txt configuration"
      exports: ["default"]
    - path: "app/lib/structured-data.ts"
      provides: "JSON-LD structured data helpers"
      exports: ["generateOrganizationSchema", "generateServiceSchema", "generateArticleSchema", "generateBreadcrumbSchema"]
  key_links:
    - from: "app/sitemap.ts"
      to: "app/data/services.ts"
      via: "import services array"
      pattern: "import.*services.*from.*data/services"
    - from: "app/sitemap.ts"
      to: "app/data/case-studies.ts"
      via: "import case studies array"
      pattern: "import.*caseStudies.*from.*data/case-studies"
    - from: "app/sitemap.ts"
      to: "app/data/blog-posts.ts"
      via: "import blog posts array"
      pattern: "import.*blogPosts.*from.*data/blog-posts"
---

<objective>
Implement comprehensive SEO infrastructure for search engine visibility.

Purpose: Enable search engines to discover, crawl, and properly index all public pages with rich snippets for improved click-through rates.

Output: Dynamic sitemap, robots.txt, structured data (JSON-LD), and meta tag audit across all pages.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

Existing data files for dynamic routes:
@app/data/services.ts
@app/data/case-studies.ts
@app/data/blog-posts.ts

Existing layouts for metadata:
@app/layout.tsx
@app/(marketing)/layout.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create sitemap.ts and robots.ts</name>
  <files>
    app/sitemap.ts
    app/robots.ts
  </files>
  <action>
Create Next.js App Router sitemap and robots files using the metadata API:

**app/sitemap.ts:**
- Export default async function returning MetadataRoute.Sitemap
- Import services from app/data/services.ts
- Import caseStudies from app/data/case-studies.ts
- Import blogPosts from app/data/blog-posts.ts
- Use NEXT_PUBLIC_SITE_URL env var with fallback to 'https://redleader.io'
- Include static pages: /, /services, /about, /contact, /case-studies, /blog
- Map dynamic routes: /services/[slug], /case-studies/[slug], /blog/[slug]
- Set appropriate lastModified dates (use publishedAt for blog posts)
- Set changeFrequency: 'weekly' for static pages, 'monthly' for blog posts
- Set priority: 1.0 for homepage, 0.8 for main sections, 0.6 for detail pages

**app/robots.ts:**
- Export default function returning MetadataRoute.Robots
- Allow all crawlers (User-Agent: *)
- Disallow /api/* paths
- Reference sitemap at ${siteUrl}/sitemap.xml
- Use same NEXT_PUBLIC_SITE_URL pattern as sitemap
  </action>
  <verify>
Run `npm run build` and check for sitemap.xml and robots.txt in output.
After build, verify files exist and contain expected content:
- sitemap.xml lists all pages with correct URLs
- robots.txt references sitemap and allows crawling
  </verify>
  <done>
Sitemap includes all 7 service pages, 3 case study pages, 3 blog posts, and 6 static pages.
Robots.txt allows crawling and references sitemap.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create structured data helpers and add JSON-LD to pages</name>
  <files>
    app/lib/structured-data.ts
    app/layout.tsx
    app/(marketing)/services/[slug]/page.tsx
    app/(marketing)/case-studies/[slug]/page.tsx
    app/(marketing)/blog/[slug]/page.tsx
  </files>
  <action>
Create structured data utility and add JSON-LD to key pages:

**app/lib/structured-data.ts:**
Create helper functions for JSON-LD schema generation:
- generateOrganizationSchema(): Organization schema with name "Red Leader", description, url, contactPoint (24/7 hotline), sameAs (social links placeholder)
- generateServiceSchema(service: Service): Service schema with name, description, provider (Organization)
- generateArticleSchema(post: BlogPost): Article schema with headline, description, author, datePublished, publisher
- generateBreadcrumbSchema(items: {name: string, url: string}[]): BreadcrumbList schema
- Export a JsonLd component that renders script tag with type="application/ld+json"

**app/layout.tsx:**
- Import and add Organization schema JSON-LD in body (global presence)
- Add before {children} so it appears on all pages

**app/(marketing)/services/[slug]/page.tsx:**
- Import generateServiceSchema and JsonLd
- Add Service + Breadcrumb schemas to the page
- Breadcrumb: Home > Services > [Service Name]

**app/(marketing)/case-studies/[slug]/page.tsx:**
- Add Breadcrumb schema: Home > Case Studies > [Title]
- (Case studies don't need specific schema type)

**app/(marketing)/blog/[slug]/page.tsx:**
- Import generateArticleSchema and JsonLd
- Add Article + Breadcrumb schemas
- Breadcrumb: Home > Blog > [Post Title]
- Use author name, publishedAt, and seoDescription from blog post data
  </action>
  <verify>
Run build and check pages render without errors.
Inspect page source to verify JSON-LD script tags present.
Use Google Rich Results Test (https://search.google.com/test/rich-results) to validate structured data on localhost using ngrok or after deploy.
  </verify>
  <done>
Organization schema appears on all pages.
Service pages have Service schema with provider.
Blog posts have Article schema with author and dates.
All detail pages have Breadcrumb schema.
  </done>
</task>

<task type="auto">
  <name>Task 3: Audit and enhance meta tags on all pages</name>
  <files>
    app/(marketing)/page.tsx
    app/(marketing)/services/page.tsx
    app/(marketing)/about/page.tsx
    app/(marketing)/contact/page.tsx
    app/(marketing)/case-studies/page.tsx
    app/(marketing)/blog/page.tsx
  </files>
  <action>
Add or enhance metadata exports on all static pages:

**General pattern for each page:**
- Export const metadata: Metadata with title, description, openGraph, twitter
- Title format: "[Page Title] | Red Leader - Emergency Infrastructure Rescue"
- Description: Unique 150-160 char description for each page
- OpenGraph: title, description, url, siteName: "Red Leader", type: "website"
- Twitter: card: "summary_large_image", title, description

**Page-specific metadata:**

**Homepage (app/(marketing)/page.tsx):**
- Already has basic metadata in app/layout.tsx, but add OG/Twitter here
- Title: "Red Leader - 24/7 Emergency Infrastructure Rescue"
- Description: "When your systems fail, we bring them back. 24/7 emergency response for Kubernetes, databases, and cloud infrastructure. Expert rescue in hours, not days."

**Services (app/(marketing)/services/page.tsx):**
- Title: "Services | Red Leader - Emergency Infrastructure Rescue"
- Description: "From emergency recovery to cloud migration and high availability design. Expert infrastructure services for enterprises who need systems that never fail."

**About (app/(marketing)/about/page.tsx):**
- Title: "About Us | Red Leader - Emergency Infrastructure Rescue"
- Description: "Meet the team that rescues failing infrastructure. 20+ years combined experience in Kubernetes, cloud platforms, and database recovery."

**Contact (app/(marketing)/contact/page.tsx):**
- Title: "Contact Us | Red Leader - Emergency Infrastructure Rescue"
- Description: "Reach us 24/7 for infrastructure emergencies. Book a consultation or call our emergency hotline for immediate assistance."

**Case Studies (app/(marketing)/case-studies/page.tsx):**
- Title: "Case Studies | Red Leader - Emergency Infrastructure Rescue"
- Description: "Real stories of infrastructure rescues. See how we recovered critical systems and saved millions for enterprises in crisis."

**Blog (app/(marketing)/blog/page.tsx):**
- Title: "Blog | Red Leader - Emergency Infrastructure Rescue"
- Description: "Technical insights on Kubernetes, databases, cloud architecture, and incident response from infrastructure experts."

NOTE: Dynamic pages ([slug] routes) likely already have generateMetadata functions using their data. Verify they follow similar patterns.
  </action>
  <verify>
Run `npm run build` to ensure no metadata errors.
View page source for each route and confirm:
- Unique title and description meta tags
- OpenGraph tags (og:title, og:description, og:url)
- Twitter card tags
  </verify>
  <done>
All 6 static pages have unique, optimized meta tags.
OpenGraph and Twitter tags present for social sharing.
Title format consistent across site.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `npm run build` succeeds without errors
2. Visit /sitemap.xml - lists all pages (should be ~20 URLs)
3. Visit /robots.txt - shows allow rules and sitemap reference
4. Inspect any page source - JSON-LD script present
5. Check meta tags in page source for each main section
</verification>

<success_criteria>
1. sitemap.xml dynamically includes all static and dynamic routes
2. robots.txt allows search engines and references sitemap
3. Organization JSON-LD on all pages
4. Service/Article schemas on appropriate detail pages
5. Breadcrumb schemas on all detail pages
6. All pages have unique meta titles and descriptions
7. OpenGraph and Twitter meta tags on all pages
</success_criteria>

<output>
After completion, create `.planning/phases/05-optimization-polish/05-01-SUMMARY.md`
</output>
